{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3106b84a-585a-43cb-82ab-4e5ce803e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import joblib \n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ce6e5-84e2-43e0-a9d7-e15885e85b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading \n",
    "df = pd.read_csv('sensor.csv', parse_dates=['timestamp'])\n",
    "\n",
    "#Split data\n",
    "train_df = df[df['timestamp'] < '2018-07-01']\n",
    "valid_df = df[(df['timestamp'] >= '2018-07-01') & (df['timestamp'] < '2018-08-01')]\n",
    "test_df = df[df['timestamp'] >= '2018-08-01'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e40e9e-dc24-484d-8c7f-3e6fd44a0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv file:\n",
    "train_df.to_csv('train.csv', index=False)\n",
    "valid_df.to_csv('valid.csv', index=False)\n",
    "test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c9398-af45-414b-b702-ba3ab6f16630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect training data\n",
    "df_train = pd.read_csv('train.csv', parse_dates=['timestamp'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae1629-9828-437f-9e3b-846bcea0ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train.isna().sum())\n",
    "# print(df_train.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d095c51-088c-475d-9867-8e46b956ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values\n",
    "percentage_missing = df_train.isnull().sum().sort_values(ascending=False)/len(df)*100\n",
    "percentage_missing.head() # show 5 largest missing %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834304e-c3fb-4973-a706-9bcf03ec07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv', parse_dates=['timestamp'])\n",
    "percentage_missing = df_test.isnull().sum().sort_values(ascending=False)/len(df)*100\n",
    "percentage_missing.head() # show 5 largest missing %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de7ebf-71e7-4251-93a8-6dc87e88db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop low quality columns\n",
    "df_train.drop(['Unnamed: 0', 'timestamp', 'machine_status'], axis=1, inplace=True)\n",
    "\n",
    "#fill NaN values\n",
    "df_train.fillna(df_train.mean(), inplace=True)\n",
    "\n",
    "#drop 'sensor_15' column\n",
    "df_train.drop('sensor_15', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e544a8-d275-4071-95b6-c69a2a0d6414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173cb9b8-1f80-44a4-85f6-96eee8ba38cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_train), columns=df_train.columns)\n",
    "\n",
    "#model\n",
    "model = IsolationForest(contamination=0.05)\n",
    "\n",
    "#model fitting\n",
    "model.fit(df_scaled)\n",
    "\n",
    "#apply trained model to data\n",
    "scores = model.decision_function(df_scaled)\n",
    "\n",
    "#saving model\n",
    "joblib.dump(model, 'model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1379d05-8a58-4a31-a04b-34cc794ce8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileProcessor:\n",
    "    def __init__(self, config_path):\n",
    "        #Load configuration\n",
    "        with open(config_path, 'r') as file:\n",
    "            self.config = json.load(file)\n",
    "        \n",
    "        self.input_directory = self.config['input_directory']\n",
    "        self.output_directory = self.config['output_directory']\n",
    "        self.image_directory = self.config['image_directory']\n",
    "        self.model_path = self.config['model_path']\n",
    "        self.scaler_path = self.config['scaler_path']\n",
    "        self.sensors_to_draw = self.config['sensors_to_draw']\n",
    "        self.check_interval = self.config['check_interval']\n",
    "        \n",
    "        #Load model and scaler\n",
    "        self.model = joblib.load(self.model_path)\n",
    "        self.scaler = joblib.load(self.scaler_path)\n",
    "        \n",
    "        #set up logging\n",
    "        logging.basicConfig(filename='file_processor.log', level=logging.INFO,\n",
    "                            format='%(asctime)s %(levelname)s %(message)s')  # Add format parameter\n",
    "    \n",
    "    def process_files(self):\n",
    "        while True:\n",
    "            try:\n",
    "                files = [f for f in os.listdir(self.input_directory) if os.path.isfile(os.path.join(self.input_directory, f))]\n",
    "                for file in files:\n",
    "                    try:\n",
    "                        logging.info(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Found new data file: {file}\")\n",
    "                        self.process_file(file)\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Error processing file {file}: {str(e)}\")\n",
    "                \n",
    "                time.sleep(self.check_interval)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Error processing files: {str(e)}\")\n",
    "    \n",
    "    def process_file(self, file):\n",
    "        try:\n",
    "            #Load data\n",
    "            file_path = os.path.join(self.input_directory, file)\n",
    "            df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])  # Convert 'timestamp' to datetime\n",
    "            df.set_index('timestamp', inplace=True)  # Set 'timestamp' as index\n",
    "            logging.info(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Loaded the file: {file}\")\n",
    "            \n",
    "            #data cleaning and preprocessing\n",
    "            df.drop(['Unnamed: 0', 'machine_status'], axis=1, inplace=True, errors='ignore')\n",
    "            df.fillna(df.mean(), inplace=True)\n",
    "            if 'sensor_15' in df.columns:\n",
    "                df.drop('sensor_15', axis=1, inplace=True)\n",
    "            \n",
    "            df_scaled = pd.DataFrame(self.scaler.transform(df), columns=df.columns)\n",
    "            logging.info(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Received transformed data\")\n",
    "            \n",
    "            #Predictions\n",
    "            predictions = self.model.predict(df_scaled)\n",
    "            df['anomaly'] = predictions\n",
    "            logging.info(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Received predictions\")\n",
    "            \n",
    "            #Save predictions\n",
    "            output_file_path = os.path.join(self.output_directory, file)\n",
    "            df.to_csv(output_file_path, index=False)\n",
    "            logging.info(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Saving predictions to {output_file_path}\")\n",
    "            \n",
    "            #save images\n",
    "            for sensor in self.sensors_to_draw:\n",
    "                if sensor in df.columns:\n",
    "                    plt.figure()\n",
    "                    plt.plot(df.index.to_numpy(), df[sensor].to_numpy())  #Convert DataFrame columns to numpy arrays\n",
    "                    plt.title(f\"{sensor} over time\")\n",
    "                    image_path = os.path.join(self.image_directory, f\"{file}-{sensor}.png\")\n",
    "                    plt.savefig(image_path)\n",
    "                    plt.close()\n",
    "                    logging.info(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Saving image {image_path}\")\n",
    "\n",
    "\n",
    "            \n",
    "            #remove the original file\n",
    "            os.remove(file_path)\n",
    "            logging.info(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Removed original file {file}\")\n",
    "            logging.info(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Resuming listening\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"{time.strftime('%Y-%m-%d %H:%M:%S')}  Error processing file {file}: {str(e)}\")\n",
    "\n",
    "\n",
    "#Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    processor = FileProcessor('application.json')\n",
    "    processor.process_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9371811-c621-459e-a483-81cf8c4574ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
